# -*- coding: utf-8 -*-
"""MNIST-classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Yo58KLC7DGyj_wOJuG4IpMTNtvYxXh4x
"""

# Description : Machine Learning classifier of MNIST handwritten digits
#               from 0-9.

!pip install tensorflow keras numpy mnist matplotlib

# Imports:
import numpy as np
import mnist as mnist
import matplotlib.pyplot as plot
from keras.models import Sequential
from keras.layers import Dense
from keras.utils import to_categorical

# Load data set:
train_images = mnist.train_images()
train_labels = mnist.train_labels()
test_images = mnist.test_images()
test_labels = mnist.test_labels()

# Normalise pixel data from [0 to 255] to [-0.5 to 0.5]:
train_images = (train_images/255) - 0.5
test_images = (test_images/255) - 0.5
# Flatten the 28x28 images into 784-dimensional vectors,
# ready to be passed into the network
train_images = train_images.reshape((-1, 784));
test_images = test_images.reshape((-1, 784));

# Build the model: 3 layers
# 2 layers with 64 neurons, RELU function
# 1 layer with 10 neurons, softmax function (output layer)

model = Sequential()
model.add( Dense(64, activation='relu', input_dim=784) )
model.add( Dense(64, activation='relu') )
model.add( Dense(10, activation='softmax') )

# Compile the model:
# Optimiser : backpropagates and trains the NN 
#             according to loss function
# Loss function : measures accuracy
# 
# Metrics : The metric by which the loss function
#           measures success

model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

#Train the model:
model.fit(
    train_images, # Training dataset
    to_categorical(train_labels), # Categorise into these labels
    epochs=5, # Number of iterations of training
    batch_size=32, #  Number of samples per gradient update
)

# Evaluate the model:
model.evaluate(
    test_images,
    to_categorical(test_labels)
)

# Save model to disk:
# model.save_weights('model.h5')

# Predict on first 5 test images
predictions = model.predict(test_images[:5])
# print predictions, extracted with argmax
print("prediction: " + str(np.argmax(predictions, axis=1)))
print("actual: " + str(test_labels[:5]))

# View images
for i in range(0,5):
  first_image = test_images[i]
  first_image = np.array(first_image, dtype='float')
  pixels = first_image.reshape((28,28))
  plot.imshow(pixels, cmap='gray')
  plot.show()